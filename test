SK Hynix 중간 이후 진행 및 완료사항 보고서
Deep learning 기반 FDC summary data auto spec 산출 알고리즘 개발

김영욱1, 안태영2, 강형구2, 윤건수1,2
포항공과대학교 물리학과1, 첨단원자력공학부2
0. 이전 진행 상황 요약
이전까지 우리는 FDC summary data의 change point detection을 수행하기 위해, 두 분포 P(x),Q(x)의 차이를 수치화하는 Shannon entropy 기반의 Kullback-Leibler divergence (이하 KLD)를 이용하였다. KLD는 다음과 같이 정의된다:
D_KL (P||Q)=∑_(x∈X)▒〖P(x)  log⁡〖P(x)/Q(x) 〗 〗=∫▒〖dx p(x)  log⁡〖p(x)/q(x) 〗 〗
KLD 값은 두 분포의 차이가 클수록 발산하는 형태로 값이 커지면 분포가 변화한 것을 관측할 수 있다. 이를 FDC 시계열 데이터에 적용하기 위해data segment를 설정하여 특정 시점을 기준으로 그 전 후의 분포 P, Q를 얻었고, 이 시점의 KLD 값을 계산하여 시계열 데이터의 분포 변화를 관측하고자 하였다.
FDC 데이터에는 여러 형태가 존재하고 이를 크게 정규 분포와 비슷한 normal, 시간에 따라 값이 증감하는 drift, 간헐적으로 특정 level의 값이 발생 하는 spike 3가지 타입으로 나누었고, 각 타입에 대해 KLD를 적용하여 시계열 KLD 값을 얻었고, 값의 변화 정도를 추적하여 change point detection을 수행하였다.
1. Kullback-Leibler divergence (KLD) 계산 알고리즘 개선
1) Kernel density estimation (KDE) based KLD
지금까지 data segment에서 P(x), Q(x)를 추정하는 방법으로 histogram을 이용하였다. KLD 계산을 위한 분포를 얻는 데 있어 기존의 방식은 bins의 크기에 따라 분포가 원 분포에서 크게 달라질 위험이 있다. 또한 시계열 KLD 계산 시 data segment의 크기가 충분히 크지 않을 경우 표본이 충분하지 않아 시계열 KLD의 노이즈가 커져 정상적인 change point detection이 어려운 경향을 보였다. 이를 고려해 data segment의 크기를 크게 하여 연속적인 히스토그램을 얻을 수 있지만, 이 경우 샘플링을 위해 더 많은 데이터가 필요하므로 real time detection을 하기에 부적합하다.
Real time detection을 위해 data segment의 크기를 줄이면서도 연속적인 히스토그램 샘플링을 위해 표본으로부터 원 분포함수를 추론하는 kernel density estimation (이하 KDE) 기법을 도입하였다. KDE는 기존 histogram 방식과 마찬가지로 관측한 data에서 직접 분포를 유추하는 non-parametric 방법이지만, kernel 함수를 이용하여 분포를 추측한다는 차이가 있다. N개의 값을 갖는1D dataset에 대해 kernel density estimation을 통해 얻는 분포는 아래와 같다:
f ̂_h (x)=1/Nh ∑_(i=1)^N▒K((x-x_i)/h)    (K is the Gaussian kernel," " h is a smoothing parameter)

Figure 1) KLD값이 크게 변할 때 KDE로 얻은 확률 분포 - 각 data segment 내 data point의 분포 (붉은색, 푸른색) 및 전체 data의 분포 (검은색)
실제 이용 시에는 두 data segment에서 domain의 범위를 얻고 data segment의 i 번째 data point x_i를 중심으로 하는 Gaussian kernel을 씌운 후, 각 data segment에서 얻은 kernel들을 전부 더하는 식으로 f ̂_h (x)를 유추한다. 우리는 histogram으로 얻은 분포를 확인했던 경험에 기반하여 Gaussian kernel을 이용하였다. 
2) KDE based KLD의 성능 향상

Figure 2) histogram 기반의 KLD와 KDE 기반의 KLD 비교 – normal 타입
Histogram 기반의 시계열 KLD 계산에서는 data segment의 크기가 일정 크기 이상으로 주어져야 유의미한 변화를 감지할 수 있다는 단점이 있었다. 반면 KDE 기반의 계산에서는 10~20개의 적은 data point만으로도 충분히 유의미한 변화를 감지하였으며 segment의 크기를 줄임으로써 time resolution을 더욱 향상시킬 수 있었다.

Figure 3) histogram 기반 KLD와 KDE 기반 KLD 결과 비교 – spike 타입
Spike type data에서도 KDE 방식을 이용했을 때 성능 향상을 보였다. Histogram 기반의 시계열 KLD 알고리즘을 spike data에 적용하면 spike의 발생이 있을 때 KLD의 값이 특정 값을 갖는 것으로 spike 발생만을 확인할 수 있었지만, KDE 기반의 KLD 알고리즘을 적용했을 경우에는 base와 spike 각각 다른 위치에서 Gaussian 분포가 발생하고, 이를 계산하므로 base와 spike의 위치를 고려한 KLD 값을 얻어, spike의 level 또한 알 수 있다.

Figure 4) histogram 기반의 KLD와 다른 smoothing parameter를 이용한 KDE 기반의 KLD 비교 – normal + spike 타입
Normal 타입과 spike 타입이 섞여있는 형태의 데이터에 대해 data segment의 크기를 data point 10개로 하여 histogram 방식 및 KDE 방식으로 시계열 KLD 값을 계산하였다. KDE 방식은 기존의 histogram 방식에 비하여 변화를 더욱 민감하게 잡아낼 수 있었다. 뿐만 아니라 kernel의 smoothing parameter를 정하는 방식에 따라 low order moment의 변화를 더욱 민감하게 감지하도록 하거나 spike point들을 민감하게 감지하도록 조절할 수 있다는 장점도 있었다.

Figure 5) histogram 기반 KLD와 KDE 기반 KLD 결과 비교 – drift 타입
Drift 타입의 경우 기존의 histogram 방식에서는 시계열 KLD 값이 특정 레벨을 기준으로 진동을 하며 변화가 커질 경우 그 진폭이 커지는 방식으로 change point detection이 가능했다. 이 경우 비정상적인 변화로 상정하기 위한 KLD의 threshold를 위 아래 모두 설정해주어야 하는 번거로움이 있었다. 반면 KDE 방식에서는 base line 레벨이 비교적 낮은 위치에 형성되어 있어 아래쪽의 threshold 가 필요하지 않으며 진동에 대한 분석 없이 KLD 값의 발산 여부로만 change point detection이 가능했다.
2. KLD 분포로부터 spec 선 설정
이번 KLD 알고리즘의 향상을 통해 이전보다 나은 변화 감지가 가능해져 normal 타입 이외의 다른 몇 가지 타입들에 대하여도 정상 상태의 기준을 마련하는 것이 용이해졌다. 여러 타입에 대하여 시계열 KLD값의 분포를 구할 수 있을 것이고, 그로부터 어느 정도의 threshold를 비정상 데이터로 볼 것인지를 결정할 spec선의 설정이 가능할 것으로 보인다.
변화가 크게 일어나는 부분에서는 KLD값이 크게 발산할 것이고 그러한 부분은 상대적으로 빈도가 적을 것이다. 즉, 그러한 변화들은 KLD의 확률 분포에서 오른쪽 끝부분에 해당하며 이를 이용하면 KLD 값의 상위 몇 퍼센트 이내의 값들을 비정상적인 변화로 보고 spec선을 설정 할 수 있다.
흔히 정규분포의 분석에서 사용하는 z-score를 차용해 spec선을 정해보았다. KLD의 확률 분포에서 평균과 표준 편차가 구해졌으며 이를 이용해 특정 z-score에 해당하는 threshold의 설정이 가능했다. 먼저 normal 타입의 데이터에 대해 z-score가 5일때를 기준으로 하여 해당 기준을 넘은 부분을 비정상적인 변화로 판단해 비정상 데이터의 위치를 표시해보았다.

Figure 6) normal 타입 데이터에 대한 KLD, KLD의 PDF 및 CDF와 그로부터 설정한 spec 선
시간에 따라 분포가 크게 바뀌지 않는 normal 타입의 경우 99%를 넘는 대부분의 data point들이 5σ 이내로 분포하였다. 초반 부분에 spec선 기준을 넘는 구간이 존재했는데 해당 부분을 정상적인 데이터로 볼 것이라면 KLD의 threshold를 보다 큰 값으로 설정하는 식으로 spec선의 조절이 가능하다.
지금까지 KLD를 여러 데이터에 적용한 경험을 기반으로 보면, KLD의 값이 4 이상인 경우 분포의 평균 값이 변하는 양상을 보였다. 전체적인 분포의 변화가 없어 KLD의 최대 값이 4를 넘지 않는 경우 KLD 값의 분포만을 이용해 spec선을 설정하게 되면 정상적인 데이터를 비정상 데이터로 감지할 가능성이 높아진다. 따라서 spec선을 설정할 때 절대적인 기준치를 함께 고려하여야 할 것으로 예상된다.

Figure 7) drift 타입 데이터에 대한 KLD, KLD의 PDF 및 CDF와 그로부터 설정한 spec 선
Drift 타입의 데이터의 경우 위의 예시와 같이 증분이 바뀌게 되면 KLD의 값이 매우 크게 발산하였다. 그러나 거의 모든 데이터 (99.99%) 가 5σ 이내에 존재하여 앞선 예시와 같이 z-score 5로 threshold를 설정하면 해당 구간을 정상적인 변화로 인식하였다. 따라서 z-score를 조금 줄일 필요성이 있었고, 3을 기준으로 threshold를 설정하게 되면 해당 구간을 비정상 변화로 인식하는 것을 확인했다. 이 경우 역시 어느 정도의 변화를 비정상 데이터로 볼 것인지에 따라 기준 z-score를 늘리거나 줄여 적합한 spec선의 설정이 가능해 질 것이다.
이처럼 데이터의 타입에 따라 비정상적인 변화로 보기 위한 KLD값의 threshold를 조금씩 상이하게 해주어야 할 것으로 예상이 된다. 각 타입별로 최적화된 spec선을 정해준다면 향후 다른 parameter에 대하여 어떤 타입인지 분석을 하게 되면 보다 수월하게 spec선의 설정이 가능할 것으로 보인다.
3. Variational autoencoder 기반의 data 타입 분류 알고리즘 개발
 
Figure 8) VAE 모델 개요 와 10-2D Gaussian mixture latent space 의 예시 
Variational autoencoder (이하 VAE)는 input data를 정확하게 재구성(decoding)하기 위한 latent space를 만드는(encoding) 인공 신경망이다. 여기서 latent space를 분석하는 것으로 input data의 추상적인 특징을 추출할 수 있는데, 우리는 이러한 VAE의 특징을 활용하는 것으로 data 타입 분류 알고리즘을 개발하였다.
보통의 VAE의 latent space는 2D Gaussian 분포에 input data가 mapping되지만, latent space의 분포를 변경하는 것으로 추상적인 특징의 차이를 더욱 두드러지게 할 수 있다.ii 우리는 2D latent space 상에서 Gaussian 샘플링을 통해 5개 레이블로 mapping한 5-2D Gaussian mixture 분포를 만들었다.
각 parameter는 chamber-process 두 인자에 따라 필터링 하여 분류하였다. VAE에는 위 두 인자에 따라 필터링 된 parameter를 20 개의 time step으로 나누어 input dataset으로 사용하였다. 이때 각 input dataset은 타입의 분류를 위해 최대값이 1, 최소값이 0을 가지도록 정규화 시켰다.
 
Figure 9) VAE로 mapping한 latent space와 각 point에서의 타입들
학습 결과 5-2D Gaussian mixture 분포에 mapping 된 VAE의 latent space는 위와 같다. 우선 latent space의 중심 부분에는 normal 형태의 데이터들이 존재한다. x축을 따라 중심에서 점점 멀어지면 데이터는 spike 형태에 가깝게 변했으며 y축을 따라 중심에서 멀어지면 데이터는 점점 step 형태에 가깝게 변하는 것이 확인되었다. 학습된 모델은 input data를 지속적으로 받아들여 latent space상에 embedding 시킴으로써 parameter의 타입을 분류할 수 있다. Latent space 상에서 서로 비슷한 형태의 데이터는 비슷한 지점에 위치하게 되므로 이를 이용하면 spec선 설정에 활용할 수 있을 것으로 예상된다.
4. Summary
KDE 를 사용하여 시계열 KLD 계산 알고리즘을 개선시켰고, 그 결과 기존의 방법보다 data segment의 크기를 줄여 보다 적은 딜레이를 가지고 감지가 가능해졌다. 뿐만 아니라 기존의 방법으로는 spec선을 설정할 때 각 타입별로 방법을 다르게 적용 했어야 하는데 개선된 KDE 기반의 KLD로는 타입에 크게 구애받지 않고 KLD의 값이 커지는 것 만으로 이상 데이터의 발생을 감지할 수 있게 됨으로써 상한의 threshold만 정해주면 spec 설정이 가능해졌다.
시간에 따라 KLD 값을 계산함으로써 시계열 형태의 KLD 데이터를 얻을 수 있었고, KLD 값의 분포를 분석하여 spec선의 설정을 시도하였다. 변화가 크게 일어나는 point는 KLD의 PDF상에서 오른쪽 끝부분에 해당할 것으로, 정규분포에서 z-score를 차용해 spec선의 설정하여 threshold를 설정하였다. 여러 타입별로 이러한 z-score의 값을 다르게 적용해주어야 할 것이며 실제의 결과와 비교하여 z-score의 값을 조정해감으로써 최적화된 spec선의 설정이 가능해 질 것이다.
타입별로 spec선을 설정하는 정도는 조금씩 상이하게 해주어야 했기 때문에 이후 VAE 알고리즘을 적용하여 주어진 FDC summary 데이터에서 각 data segment를 여러 타입으로 분류하는 작업을 거쳤다. VAE의 latent space상에서 segment의 위치를 통해 그 segment의 타입을 결정할 수 있었다. 각 센서 별로 설정한 FDC spec 을 latent space에 mapping 하여 그 spec 의 적절성을 판단할 수 있을 것으로 기대한다.
